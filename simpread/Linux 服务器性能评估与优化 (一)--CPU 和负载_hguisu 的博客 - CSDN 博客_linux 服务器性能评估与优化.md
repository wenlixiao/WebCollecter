> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [guisu.blog.csdn.net](https://guisu.blog.csdn.net/article/details/39373311)

> 之前文章《Linux 服务器性能评估与优化 (一)》太长，阅读不方便，因此拆分成系列博文：《Linux 服务器性能评估与优化 (一)--CPU》《Linux 服务器性能评估与优化 (二)-- 内存》《Linux 服务器......

之前文章[《Linux 服务器性能评估与优化 (一)》](https://blog.csdn.net/hguisu/article/details/39373311 "《Linux服务器性能评估与优化(一)》")太长，阅读不方便，因此拆分成系列博文：

[《](https://blog.csdn.net/hguisu/article/details/39373311 "《")[Linux 服务器性能评估与优化 (一)--CPU](https://blog.csdn.net/hguisu/article/details/39373311 "Linux服务器性能评估与优化(一)--CPU")[》](https://blog.csdn.net/hguisu/article/details/39373311 "》")

[《](https://blog.csdn.net/hguisu/article/details/39373311 "《")[Linux 服务器性能评估与优化 (二)-- 内存](https://blog.csdn.net/hguisu/article/details/102620787 "Linux服务器性能评估与优化(二)--内存")[》](https://blog.csdn.net/hguisu/article/details/39373311 "》")

[《](https://blog.csdn.net/hguisu/article/details/102620903 "《")[Linux 服务器性能评估与优化 (三)-- 磁盘 i/o](https://blog.csdn.net/hguisu/article/details/102620903 "Linux服务器性能评估与优化(三)--磁盘i/o")[》](https://blog.csdn.net/hguisu/article/details/39373311 "》")

[《](https://blog.csdn.net/hguisu/article/details/102620981 "《")[Linux 服务器性能评估与优化 (四)-- 网络](https://blog.csdn.net/hguisu/article/details/39373311 "Linux服务器性能评估与优化(四)--网络")[》](https://blog.csdn.net/hguisu/article/details/39373311 "》")

[《](https://blog.csdn.net/hguisu/article/details/39249775 "《")[Linux 服务器性能评估与优化（五)-- 内核参数](https://blog.csdn.net/hguisu/article/details/39249775 "Linux服务器性能评估与优化（五)--内核参数")[》](https://blog.csdn.net/hguisu/article/details/39373311 "》")

### **1.1、影响 Linux** 服务器性能的因素 

  **1.** **操作系统级**

        性能调优是找出系统瓶颈并消除这些瓶颈的过程。 很多系统管理员认为性能调优仅仅是调整一下内核的参数即可解决问题， 事实上情况并不是这样。 性能调优是实现操作系统的各个子系统之间的平衡性，这些子系统包括：

Ø       CPU

Ø       [内存](https://so.csdn.net/so/search?q=%E5%86%85%E5%AD%98&spm=1001.2101.3001.7020)

Ø       磁盘 I/O 带宽

Ø       网络 I/O 带宽

子系统之间相互依存，任何一个子系统的负载过度都能导致其他子系统出现问题，例如：  
* 大量的 page-in IO 请求可能导致内存队列被塞满  
* 网卡的巨量吞吐可能导致 CPU 资源耗尽  
* 系统尝试保持释放内存队列时可能耗尽 CPU 资源  
* 来自内存的大量磁盘写入请求可能导致 CPU 资源和 IO 通道耗尽

性能调优的前提是找出系统瓶颈之所在， 尽管问题看似由某个子系统所导致， 然而这很可能是另外一个子系统的过载所引起的。

**2.    程序应用级**

 为了明白从何处开始着手调整性能瓶颈， 弄清被分析系统的性能表现是首要任务。 任何系统的应用常可分为以下两类：  
1） IO 限制型——一个 IO 限制型的应用需要大量的内存和基础存储设备占用。 因其需要大量的数据读写请求，此类应用对 CPU 和网络需求不高（除非存储系统在网络上） 。  
       IO 限制型应用使用 CPU 资源来进行 IO 操作且常进入睡眠状态。 数据库应用常被认为属于此类。

  
2）CPU 限制型——一个 CPU 限制型应用需要大量的 CPU 资源，来进行批量的处理或大量的计算。大容量 web 服务，mail 服务，以及任何类型的渲染服务都被归到此类。

### **1.2、系统性能评估标准**

        判断一个系统是否有性能问题的唯一途径是弄清楚对系统的期望是神马， 需求的性能是神马， 应该得到的数据是神马？而为了建立这些信息的唯一途径是为系统建立一个基准。 在性能可接受的状态下必须为系统建立统计信息，这样就可以在性能不可接受时进行对比。

<table><tbody><tr><td rowspan="2"><p>影响性能因素</p></td><td colspan="3"><p>评判标准</p></td></tr><tr><td><p>好</p></td><td><p>坏</p></td><td><p>糟糕</p></td></tr><tr><td><p>CPU</p></td><td><p>user% + sys%&lt; 70%</p></td><td><p>user% + sys%= 85%</p></td><td><p>user% + sys% &gt;=90%</p></td></tr><tr><td><p>内存</p></td><td><p>Swap In（si）＝0</p><p>Swap Out（so）＝0</p></td><td><p>Per CPU with 10 page/s</p></td><td><p>More Swap In &amp; Swap Out</p></td></tr><tr><td><p>磁盘</p></td><td><p>iowait % &lt; 20%</p></td><td><p>iowait % =35%</p></td><td><p>iowait % &gt;= 50%</p></td></tr></tbody></table>

其中：

       %user：表示 CPU 处在用户模式下的时间百分比。

       %sys：表示 CPU 处在[系统](http://www.baidu.com/baidu?tn=jbh270&word=site:33369.com%20 "系统")模式下的时间百分比。

       %iowait：表示 CPU 等待输入输出完成时间的百分比。

       swap in：即 si，表示虚拟内存的页导入，即从 SWAP DISK 交换到 RAM

       swap out：即 so，表示虚拟内存的页导出，即从 RAM 交换到 SWAP DISK。

### 1.3、系统性能分析工具

![](https://img-blog.csdn.net/20140918220449640?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaGd1aXN1/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

**1. 常用系统命令** 

Vmstat、sar、iostat、netstat、free、ps、top 等

**2. 常用组合方式** 

•  用 vmstat、sar、iostat 检测是否是 CPU 瓶颈

•  用 free、vmstat 检测是否是内存瓶颈

• 用 iostat 检测是否是磁盘 I/O 瓶颈

•  用 netstat 检测是否是网络带宽瓶颈 (netstat -nat | awk 'FNR>2{print $NF}' | sort | uniq -c) 

             netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'

**Linux 性能评估与优化：cpu，内存，IO, 网络**

**系统工具图：**

![](https://img-blog.csdnimg.cn/20190605165415425.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ndWlzdS5ibG9nLmNzZG4ubmV0,size_16,color_FFFFFF,t_70)

### **2.1 系统整体性能评估（uptime 命令 / top）**

# uptime

16:38:00 up 118 days,  3:01,  5 users,  load average: 1.22, 1.02, 0.91

这里需要注意的是：load average 这个输出值，这三个值的大小一般不能大于系统 CPU 的个数，例如，本输出中系统有 8 个 CPU, 如果 load average 的三个值长期大于 8 时，说明 CPU 很繁忙，负载很高，可能会影响系统性能，但是偶尔大于 8 时，倒不用担心，一般不会影响系统性能。相反，如果 load average 的输出值小于 CPU 的个数，则表示 CPU 还有空闲的时间片，比如本例中的输出，CPU 是非常空闲的。

**Load：top**

系统负载指运行队列的平均长度，也就是等待 CPU 的平均进程数。Load 越高说明系统响应越慢，如果 load 是 0，代表进程不需要等待，立刻就能获得 cpu 运行。可以通过查询文件 / proc/loadavg 获取系统在前一分钟、前五分钟和前十五分钟的平均负载以及当前运行的进程、系统的进程数和上一次调度运行的进程。

justin@junjun:/proc$ cat/proc/loadavg

0.71 0.70 0.63 1/403 5111

在 linux 系统中，也可直接通过命令行 “w”或者 “uptime” 查看，如下：

16:10:22 up 1 day, 4:18,  3 users,  load average: 0.34, 0.50, 0.52

USER     TTY      FROM              LOGIN@  IDLE   JCPU   PCPU WHAT

justin   tty7     :0               Tue11   28:19m 10:15   0.22s gnome-session

justin   pts/0    :0.0             Tue11   28:17m 2:22   0.00s /bin/bash./jettyctl.sh

justin   pts/1    :0.0             16:08    0.00s 0.17s  0.00s w

**cpu usage：**

系统的 CPU 使用率。

可以用 “top” 命令动态的显示当前系统进程用户的使用情况。

![](https://img-blog.csdnimg.cn/20191018094413335.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hndWlzdQ==,size_16,color_FFFFFF,t_70)

前五行是系统整体的统计信息。

第一行是任务队列信息，同 uptime 命令的执行结果。其内容如下：当前时间；系统运行时间，格式为时: 分；当前登录用户数；系统负载，即任务队列的平均长度。

第二、三行为进程和 CPU 的信息。当有多个 CPU 时，这些内容可能会超过两行。

内容如下：Tasks: 175 total 进程总数；1 running 正在运行的进程数；174 sleeping 睡眠的进程数；0 stopped 停止的进程数；0 zombie 僵尸进程数

Cpu(s):22.0% us 用户空间占用 CPU 百分比

20.7%sy 内核空间占用 CPU 百分比

1.1%ni 用户进程空间内改变过优先级的进程占用 CPU 百分比

52.7%id 空闲 CPU 百分比

3.3%wa 等待输入输出的 CPU 时间百分比

0.0%hi

0.2%si swap in，表示虚拟内存的页导入，即从 SWAPDISK 交换到 RAM

0.0%st swap out，表示虚拟内存的页导出，即从 RAM 交换到 SWAPDISK。

PR：操作系统给进程的安排的优先级。这个值标示进程调度器分配给进程的时间片长度。单位是时钟个数。如果一个 Linux 系统的时间片是 10ms，那么 PID 是 2718 的进程在执行了 200ms 后，才会进行进程切换。 

RES：进程占用的物理内存大小             

VIRT：物理内存 + 虚拟内存。                                                                        

**吞吐率：**

服务器单位时间内处理的请求数，一般用来描述并发能力，当然谈吞吐率的前提是并发用户数。不同的并发用户数下，吞吐率自然大不相同。单位是 “请求数 / 秒”。吞吐量分为网络吞吐量和事务吞吐量，当作为事务吞吐量时，采用 TPS 来衡量。目前线上环境 Apache 没有 mod_status 模块，不能很方便的查询。

**TPS：**

服务器每秒处理的事务数。PV 在性能测试中的表现形式是以 TPS 来体现的，两者有一个转换公式，如下：

TPS 平均值 =((PV*80%)/(24*60*60*40%))/ 服务器数量 =  pv/s

TPS 峰值 =(((PV*80%)/(24*60*60*40%))*1.6) / 服务器数量 =  pv/s ，这个和我们经常说的 “2-8 原则” 贴近。

一般的，评价系统性能均以每秒钟完成的技术交易的数量来衡量。系统整体处理能力取决于处理能力最低模块的 TPS 。应用系统的处理能力一般要求在 10-100 左右。

介绍在 top 命令执行过程中可以使用的一些交互命令。从使用角度来看，熟练的掌握这些命令比掌握选项还重要一些。这些命令都是单字母的，如果在命令行选项中使用了 s 选项，则可能其中一些命令会被屏蔽掉。  
<空格>; 立即刷新显示。  
Ctrl+L 擦除并且重写屏幕。  
h 或者? 显示帮助画面，给出一些简短的命令总结说明。  
k 终止一个进程。系统将提示用户输入需要终止的进程 PID，以及需要发送给该进程什幺样的信号。一般的终止进程可以使用 15 信号；如果不能正常结束那就使用信号 9 强制结束该进程。默认值是信号 15。在安全模式中此命令被屏蔽。  
i 忽略闲置和僵死进程。这是一个开关式命令。  
q 退出程序。  
r 重新安排一个进程的优先级别。系统提示用户输入需要改变的进程 PID 以及需要设置的进程优先级值。输入一个正值将使优先级降低，反之则可以使该进程拥有更高的优先权。默认值是 10。  
S 切换到累计模式。  
s 改变两次刷新之间的延迟时间。系统将提示用户输入新的时间，单位为 s。如果有小数，就换算成 ms。输入 0 值则系统将不断刷新，默认值是 5 s。需要注意的是如果设置太小的时间，很可能会引起不断刷新，从而根本来不及看清显示的情况，而且系统负载也会大大增加。  
f 或者 F 从当前显示中添加或者删除项目。  
o 或者 O 改变显示项目的顺序。  
l 切换显示平均负载和启动时间信息。  
m 切换显示内存信息。  
t 切换显示进程和 CPU 状态信息。  
c 切换显示命令名称和完整命令行。  
**M 根据驻留内存大小进行排序：查看最耗内存的进程  
P 根据 CPU 使用百分比大小进行排序：查看最耗 cpu 的进程  
T 根据时间 / 累计时间进行排序。**  
W 将当前设置写入~/.toprc 文件中。这是写 top 配置文件的推荐方法。

### 3.1、CPU 介绍

       CPU 利用率很大部分取决于试图访问它的资源， 内核拥有一个管理两种资源的调度器：线程（单或多）和中断。调度器给予不同资源以不同的优先级，以下由优先级从高到低：

1） 中断——设备通知内核它们处理完成。例如网卡发送一个数据包或硬盘驱动器提供一次 IO 请求  
2） 内核（系统）进程——所有的内核进程都在此级别的优先级进行处理  
3）用户进程——通常被称为 “用户空间” ，所有应用软件运行在用户空间，拥有最低的优先级

**为了弄明白内核是如何管理不同的资源的，几个关键概念需要提及一下： context  switches，run queues，utilization。**

**Context Switches(上下文切换)：进程调度**

 **CPU 切换到另一个进程需要保存当前进程的状态并恢复另一个进程的状态：当前运行任务转为就绪（或者挂起、中断）状态，另一个被选定的就绪任务成为当前任务。进程调度包括保存当前任务的运行环境，恢复将要运行任务的运行环境。**

        大多数处理器在同一时间只能处理一个进程或线程，多线程处理器可同时处理 n 个线程。然而，linux 内核把多核处理器的各个核心当做独立核心。例如，内核把一个双核的处理当做两个独立处理器。

         一个标准的内核可同时处理 50 到 50000 个进程， 在只有一颗 CPU 的情况下， 内核必须调度和平衡这些进程和线程。 每个线程在处理器上都拥有一个时间分配单元， 当一个线程超过自己的时间单元或被更高优先级的程序抢占时， 此线程及被传回队列而此时更高优先级的程序将在处理器上执行。这种线程间的切换操作即是上下文切换。

       在 linux 内核中，每一个进程都存在一个名为 “进程描述符” 的管理表。该进程描述符会调整为按照优先级降序排序，已按合理的顺序运行进程（任务）。

进程状态：

       运行态（running） 只要 cpu 空闲，任何时候都可以运行  
       可中断睡眠（interruptible） 为恢复时间无法预测的长时间等待状态。如，来自于键盘设备的输入。  
       不可中断睡眠:（uninterruptible） 主要为短时间时的等待状态。被 IO 阻塞的进程，例如等待磁盘 IO，网络 IO，或者一个系统调用等待内核空间的返回。  
       就绪态（runnable） 响应暂停信号而运行的中断状态。  
       僵死态（zombie） 进程都是由父进程创建，并销毁；在父进程没有销毁其子进程，被销毁的时候，其子进程由于没有父进程被销毁，就会转变为僵死态。

**运行队列：负载**  
      每个 CPU 维持着一个线程的运行队列， 理论上， 调度器应该是不断地运行和执行线程。线程要么处于睡眠状态，要么处于可运行状态。假如 CPU 子系统处于高负载状态，那么内核调度器罢工是有可能的， 其结果将导致可运行状态的进程开始阻塞运行队列。 运行队列越大，执行进程所花费的时间也越长。  
一个很流行的术语叫 “load（负载）” 经常被用来描述运行队列的状态，系统负载是由正在执行的进程和 CPU 运行队列中的进程的结合，如果有 2 个线程正在一个双核系统中执行且 4 个正在运行队列中， 那么负载数即是 6， 像 top 等工具可查看过去 1,5,15 分钟的负载均值。

      **load average 值包括：**使用 man uptime 命令看一下 Linux 对于 load 的解释：

![](https://img-blog.csdnimg.cn/51ca6525926c4c068f4bca5a051aed2b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAaGd1aXN1,size_20,color_FFFFFF,t_70,g_se,x_16)

大致意思就是说，系统 load 是处于运行状态或者不可中断状态的进程的平均数。一个处于运行状态的进程表示**正在使用 cpu 或者等待使用 cpu**，一个不可中断状态的进程表示**正在等待 IO**，例如磁盘 IO。也就是下面这两种情况的进程才会表现为负载的值：  
      1）进程处于状态是 R（运行态 running）：**正在使用 CPU 和等待使用 CPU（其他进程用完 cpu）** 2）不可中断状态 D（D 状态 uninterruptible）：**进程需要继续处理，但需等待 IO（磁盘输入输出完成才能进行）。**  
   一般来说 Load 简单的计算就是 2* CPU 个数减去 1-2 左右（这个只是网上看来的，未必是一个标准）。

**CPU 利用率**  
CPU 利用率被定义为 CPU 使用的百分比， CPU 如何被利用是衡量一个系统的重要标准。多数性能监测工具把 CPU 利用分为以下几个类型：  
* 用户时间——CPU 花在执行用户空间进程的时间百分比  
* 系统时间——CPU 花在执行内核进程和中断的时间百分比  
* IO 等待——CPU 花在等待 IO 请求完成的时间百分比  
* IDLE——CPU 的空闲时间百分比

CPU 的使用率 = (%us + %sy + %ni)

理解 CPU 的性能状态即是理解中断，运行队列和上下文切换的状态。之前有提到过性能与基准信息有密切关系，但是有些常规的性能预期：  
* 运行队列——每个处理器上的运行队列不应该有超过 1-3 个排队的线程。 例如， 一个双核系统不应该有超过 6 个进行在运行队列里。  
* CPU 利用率——假如一个 CPU 满状态负荷，那么以下的平衡关系需要达到：  
    65%--70% 的用户时间  
    30%--35% 的系统时间  
    0%--5% 的空闲时间  
* 上下文切换——上下文切换的数量与 CPU 的利用率有直接关系。如果 CPU 处于高负荷状态下那么大量的上下文切换是正常的。

### **3.2、利用 vmstat 命令监控系统 CPU**

   vmstat 工具的低开销使得它可以在一个高负载的系统上持续运行，它有两种工作模式：均值模式和采样模式。采样模式如下：

   该命令可以显示关于系统各种资源之间相关性能的简要信息，这里我们主要用它来看 CPU 一个负载情况。

   下面是 vmstat 命令在某个系统的输出结果：

[root@node1 ~]# vmstat 2 3

procs -----------memory----------  ---swap--  -----io---- --system--  -----cpu------

 r  b   swpd   free      buff  cache   si   so    bi    bo       in     cs     us sy  id   wa st

 0  0    0    162240   8304  67032   0    0    13    21   1007   23     0  1   98   0   0

 0  0    0    162240   8304  67032   0    0     1     0     1010   20     0  1   100 0   0

 0  0    0    162240   8304  67032   0    0     1     1     1009   18     0  1    99  0   0

**Procs**

     r：运行和等待 cpu 时间片的进程数，这个值如果长期大于系统 CPU 的个数，说明 CPU 不足，需要增加 CPU。

     b：在等待资源的进程数，比如正在等待 I/O、或者内存交换等。其实就是阻塞的进程。

**Memory**

     swpd: 虚拟内存使用情况，单位：KB

     free: 空闲的内存，单位 KB

     buff: 被用来做为缓存的内存数，一般对块设备的读写才需要缓冲，单位：KB

     cache: 表示 page cached 的内存数量，一般作为文件系统 cached，频繁访问的文件都会被 cached，如果 cache 值较大，说明 cached 的文件数较多，如果此时 IO 中 bi 比较小，说明文件系统效率比较好。

**Swap：如果大于 0，表示你的机器物理内存不足了，如果不是程序内存泄露的原因，那么你该升级内存了或者把耗内存的任务迁移到其他机器。**

     si: 从磁盘交换到内存的交换页数量，单位：KB / 秒。如果这个值大于 0，表示物理内存不够用或者内存泄露了，要查找耗内存进程解决掉。

     so: 从内存交换到磁盘的交换页数量，单位：KB / 秒。如果这个值大于 0，同上。

**I/O**

     bi: 发送到块设备的块数，单位：块 / 秒

     bo: 从块设备接收到的块数，单位：块 / 秒。例如我们读取文件，bo 就要大于 0。bi 和 bo 一般都要接近 0，不然就是 IO 过于频繁，需要调整。

**[符设备和块设备的区别](http://blog.chinaunix.net/uid-24612962-id-3779969.html "符设备和块设备的区别") ：**

     设备文件分为 Block Device Driver 和 Character Device Drive 两类。Character Device Drive 又被称为字符设备或裸设备 raw devices; Block Device Driver 通常成为块设备。而 Block Device Driver 是以固定大小长度来传送转移资料 ；Character Device Driver 是以不定长度的字元传送资料 。且所连接的 Devices 也有所不同，Block Device 大致是可以随机存取 (Random Access) 资料的设备，如硬碟机或光碟机；而 Character Device 刚好相反，依循先後顺序存取资料的设备，如印表机 、终端机等皆是。

       /dev/dsk 对应的为块设备，文件系统的操作用到它，如 mount。/dev/rdsk 对应的为字符设备 (裸设备，rdsk 的 r 即为 raw)，fsck newfs 等会涉及到。一般我们的操作系统和各种软件都是以块方式读写硬盘，这里的块是逻辑块，创建文件系统时可以选择，windows 里叫簇。可看 newfs or mkfs 的 manual。oracle 是比较常见的字符方式读写硬盘。

       字符设备还是块设备的定义属于操作系统的设备访问层，与实际物理设备的特性无必然联系。设备访问层下面是驱动程序，所以只要驱动程序提供的方式，都可以。 也就是说驱动程序支持 stream 方式，那么就可以用这种方式访问，驱动程序如果还支持 block 方式，那么你想用哪种方式访问都可以，典型的比如硬盘式 的裸设备，两种都支持块设备（block device）：是一种具有一定结构的随机存取设备，对这种设备的读写是按块进行的，他使用缓冲区来存放暂时的数据，待条件成熟后，从缓存一次性写入设备 或从设备中一次性读出放入到缓冲区，如磁盘和文件系统等字符设备（Character device）：这是一个顺序的数据流设备，对这种设备的读写是按字符进行的，而且这些字符是连续地形成一个数据流。他不具备缓冲区，所以对这种设备的读 写是实时的，如终端、磁带机等。

      系统中能够随机（不需要按顺序）访问固定大小数据片（chunks）的设备被称作块设备，这些数据片就称作块。最常见的块设备是硬盘，除此以外，还有软盘驱 动器、CD-ROM 驱动器和闪存等等许多其他块设备。注意，它们都是以安装文件系统的方式使用的——这也是块设备一般的访问方式。

       另一种基本的设备类型是字符设备。字符设备按照字符流的方式被有序访问，像串口和键盘就都属于字符设备。如果一个硬件设备是以字符流的方式被访问的话，那就应该将它归于字符设备；反过来，如果一个设备是随机（无序的）访问的，那么它就属于块设备。

       这两种类型的设备的根本区别在于它们是否可以被随机访问——换句话说就是，能否在访问设备时随意地从一个位置跳转到另一个位置。举个例子，键盘这种设备提供 的就是一个数据流，当你敲入 “fox” 这个字符串时，键盘驱动程序会按照和输入完全相同的顺序返回这个由三个字符组成的数据流。如果让键盘驱动程序打乱顺 序来读字符串，或读取其他字符，都是没有意义的。所以键盘就是一种典型的字符设备，它提供的就是用户从键盘输入的字符流。对键盘进行读操作会得到一个字符 流，首先是“f”，然后是“o”，最后是“x”，最终是文件的结束(EOF)。当没人敲键盘时，字符流就是空的。硬盘设备的情况就不大一样了。硬盘设备的 驱动可能要求读取磁盘上任意块的内容，然后又转去读取别的块的内容，而被读取的块在磁盘上位置不一定要连续，所以说硬盘可以被随机访问，而不是以流的方式 被访问，显然它是一个块设备。

       内核管理块设备要比管理字符设备细致得多，需要考虑的问题和完成的工作相比字符设备来说要复杂许多。这是因为字符设备仅仅需要控制一个位置—当前位置—而 块设备访问的位置必须能够在介质的不同区间前后移动。所以事实上内核不必提供一个专门的子系统来管理字符设备，但是对块设备的管理却必须要有一个专门的提 供服务的子系统。不仅仅是因为块设备的复杂性远远高于字符设备，更重要的原因是块设备对执行性能的要求很高；对硬盘每多一分利用都会对整个系统的性能带来 提升，其效果要远远比键盘吞吐速度成倍的提高大得多。另外，我们将会看到，块设备的复杂性会为这种优化留下很大的施展空间。

[linux 驱动程序中字符设备和块设备的三点区别](http://www.cnblogs.com/civet/archive/2011/03/19/1988909.html "linux驱动程序中字符设备和块设备的三点区别")
------------------------------------------------------------------------------------------------------------------

1. 字符设备只能以字节为最小单位访问，而块设备以块为单位访问，例如 512 字节，1024 字节等

2. 块设备可以随机访问，但是字符设备不可以

3. 字符和块没有访问量大小的限制，块也可以以字节为单位来访问

**System**

      in: 每秒的中断数，包括时钟中断。

      cs（context switch）: 每秒的环境（上下文）切换次数。例如我们调用系统函数，就要进行上下文切换，线程的切换，也要进程上下文切换，这个值要越小越好，太大了，要考虑调低线程或者进程的数目, 例如在 apache 和 nginx 这种 web 服务器中，我们一般做性能测试时会进行几千并发甚至几万并发的测试，选择 web 服务器的进程可以由进程或者线程的峰值一直下调，压测，直到 cs 到一个比较小的值，这个进程和线程数就是比较合适的值了。系统调用也是，每次调用系统函数，我们的代码就会进入内核空间，导致上下文切换，这个是很耗资源，也要尽量避免频繁调用系统函数。上下文切换次数过多表示你的 CPU 大部分浪费在上下文切换，导致 CPU 干正经事的时间少了，CPU 没有充分利用，是不可取的。

**cpu**

    us：用户进程消耗的 CPU 时间百分比。us 的值比较高时，说明用户进程消耗的 cpu 时间多，但是如果长期大于 50%，就需要考虑优化程序或算法。

     sy：内核进程消耗的 CPU 时间百分比。Sy 的值较高时，说明内核消耗的 CPU 资源很多，即系统调用（system call）时间长，例如是 IO 操作频繁。

根据经验，us+sy 的参考值为 70%，如果 us+sy 大于 70% 说明可能存在 CPU 资源不足。

  wt：等待 IO CPU 时间

注意：

            1）如果 r （run queue 运行队列中的进程数）经常大于 4 ，且 id 经常少于 40，表示 cpu 的负荷很重。

            2）如果 si，so 长期不等于 0，表示内存不足。

            3）如果 disk 经常不等于 0， 且在 b 中的队列大于 3， 表示 io 性能不好。

           4）其拥有很高的中断数 （in） 和很低的上下文切换数， 这说明可能有单个进程在进行大量的硬件资源请求。  
            5）运行队列数刚好达到可接受的上限值，且出现超过上限值的情况。

**什么场景会造成负载很高但 **CPU 低**？**

负载总结为一句话就是：需要运行处理但又必须等待队列前的进程处理完成的进程个数。具体来说，也就是如下两种情况：  
1）等待被授权予 CPU 运行权限的进程  
2）等待磁盘 I/O 完成的进程  
ps -eLf 可以查看系统的线程。

cpu 低而负载高也就是说等待磁盘 I/O 完成的进程过多，就会导致队列长度过大，这样就体现到负载过大了，但实际是此时 cpu 被分配去执行别的任务或空闲，通过以下命令查看：

> 1、IOWAIT: 通过 top 命令查看 CPU 等待 IO 时间，即 %wa；
> 
> 2、磁盘 IO: 通过 iostat -d -x -m 1 10 查看磁盘 IO 情况；
> 
> 3、网络 IO: 通过 sar -n DEV 1 10 查看网络 IO 情况；
> 
> 通过如下命令查找占用 IO 的程：
> 
> ps -e -L h o state,cmd  | awk '{if($1=="R"||$1=="D"){print $0}}' | sort | uniq -c | sort -k 1nr

具体场景有如下几种。

场景 1：内存耗尽，如果没有开启 swap 内存，也将会导致负载特别高，cpu 使用很低。

场景 2：磁盘读写请求过多就会导致大量 I/O 等待  
cpu 的工作效率要高于磁盘，而进程在 cpu 上面运行需要访问磁盘文件，这个时候 cpu 会向内核发起调用文件的请求，让内核去磁盘取文件，这个时候会切换到其他进程或者空闲，这个任务就会转换为不可中断睡眠状态。当这种读写请求过多就会导致不可中断睡眠状态的进程过多，从而导致负载高，cpu 低的情况。

场景 3：MySQL 中存在没有索引的语句或存在死锁等情况  
我们都知道 MySQL 的数据是存储在硬盘中，如果需要进行 sql 查询，需要先把数据从磁盘加载到内存中。当在数据特别大的时候，如果执行的 sql 语句没有索引，就会造成扫描表的行数过大导致 I/O 阻塞，或者是语句中存在死锁，也会造成 I/O 阻塞，从而导致不可中断睡眠进程过多，导致负载过大。  
具体解决方法可以在 MySQL 中运行 show full processlist 命令查看线程等待情况，把其中的语句拿出来进行优化。

场景 4：外接硬盘故障，常见有挂了 NFS，但是 NFS server 故障  
比如我们的系统挂载了外接硬盘如 NFS 共享存储，经常会有大量的读写请求去访问 NFS 存储的文件，如果这个时候 NFS Server 故障，那么就会导致进程读写请求一直获取不到资源，从而进程一直是不可中断状态，造成负载很高。  
场景 5：访问第三方 api 接口  
如果我们访问第三方 http api，例如接口的响应时间很慢，readTimeout=2000ms，在高并发的情况下，很多线程都被中断等待 api 的网络 IO。导致 cpu 使用率很低，但是 load 很高。

场景五：系统出现大量的僵死进程：

![](https://img-blog.csdnimg.cn/20181218170659655.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hndWlzdQ==,size_16,color_FFFFFF,t_70)

解决办法：  
出现此种情况时，可能是由于僵死进程导致的。可以通过指令 ps -axjf  查看是否存在 D 状态进程。  
D 状态是指不可中断的睡眠状态。该状态的进程无法被 kill，也无法自行退出。只能通过恢复其依赖的资源或者重启系统来解决。

**什么场景会造成** **CPU 跑满：**

**CPU 的跑满或跑高**

**1）普通进程占用很高，可以直接 kill 掉**

**2）kswapd0 进程导致的内存不足等问题，您需要对系统进行规格的升级或程序的优化。（内存优化章节有说明）**

### kswapd0 进程占用导致 CPU 较高

操作系统都用分页机制来管理物理内存，系统会把一部分硬盘空间虚拟成内存使用。由于内存的速度要比磁盘快得多，所以系统要按照某种换页机制将不需要的页面换到磁盘中，将需要的页面调到内存中。

kswapd0 是虚拟内存管理中负责换页的进程，当服务器内存不足的时候 kswapd0 会执行换页操作，这个换页操作是十分消耗主机 CPU 资源的。

### 3.3、mpstat 命令监控系统 CPU

如果你的系统有多个处理器核心，你就可以使用 mpstat 工具来监测每个核心。linux 内核把一个双核处理器当做 2 个 CPU，所以一个拥有 2 颗双核心的系统将被视为 4CPU。

# mpstat –P ALL 1

10:48:59 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest   %idle  
10:48:59 PM  all    0.32    0.00    0.22    0.07    0.01    0.01    0.00    0.00   99.37

### **3.4、利用 sar 命令监控系统 CPU**

sar 功能很强大，可以对系统的每个方面进行单独的统计，但是使用 sar 命令会增加系统开销，不过这些开销是可以评估的，对系统的统计结果不会有很大影响。

 下面是 sar 命令对某个系统的 CPU 统计输出：

[root@webserver ~]# sar -u 3 5

Linux 2.6.9-42.ELsmp (webserver)        11/28/2008      _i686_  (8 CPU)

11:41:24 AM     CPU     %user     %nice   %system   %iowait    %steal     %idle

11:41:27 AM     all      0.88      0.00      0.29      0.00      0.00     98.83

11:41:30 AM     all      0.13      0.00      0.17      0.21      0.00     99.50

11:41:33 AM     all      0.04      0.00      0.04      0.00      0.00     99.92

11:41:36 AM     all      **90.08     0.00      0.13      0.16      0.00     9.63**

11:41:39 AM     all      0.38      0.00      0.17      0.04      0.00     99.41

Average:        all      0.34      0.00      0.16      0.05      0.00     99.45      

如果是查看每个核心的状况，也可以使用

```
sar -P ALL 1 1

```

对上面每项的输出解释如下：

l        %user 列显示了用户进程消耗的 CPU 时间百分比。

l        %nice 列显示了运行正常进程所消耗的 CPU 时间百分比。

l        %system 列显示了系统进程消耗的 CPU 时间百分比。

l        %iowait 列显示了 IO 等待所占用的 CPU 时间百分比

l        %steal 列显示了在内存相对紧张的环境下 pagein 强制对不同的页面进行的 steal 操作 。

l        %idle 列显示了 CPU 处在空闲状态的时间百分比。

 **具体参考**：**LinuxCPU 利用率计算原理及内核实现** ([Linux CPU 利用率计算原理及内核实现 – Linux Kernel Exploration](http://ilinuxkernel.com/?p=333 "Linux CPU利用率计算原理及内核实现 – Linux Kernel Exploration"))

问题

1. **你是否遇到过系统 CPU 整体利用率不高，而应用缓慢的现象？**

       在一个多 CPU 的系统中，如果程序使用了单线程，会出现这么一个现象，CPU 的整体使用率不高，但是系统应用却响应缓慢，这可能是由于程序使用单线程的原因，单线程只使用一个 CPU，导致这个 CPU 占用率为 100%，无法处理其它请求，而其它的 CPU 却闲置，这就导致了整体 CPU 使用率不高，而应用缓慢现象的发生。

### 3.5、小结

CPU 的性能监测包含以下部分：  
* 1）检查系统运行队列并确保每个核心上不超过 3 个可运行进程  
* 2）确保 CPU 利用率的用户时间和系统时间在 70/30 之间  
* 3）当 CPU 花费更多的时间在 system mode 上时，更有可能是因过载而试图重新调度优先级  
* 4）运行 CPU 限制型应用比 IO 限制型应用更易出现性能瓶颈

**QPS** =  请求数 / 秒：每秒钟处理完请求的次数；注意这里是处理完，具体是指发出请求到服务器处理完成功返回结果。

**TPS**：每秒钟处理完的事务次数，一般 TPS 是对整个系统来讲的。一个应用系统 1s 能完成多少事务处理，一个事务在分布式处理中，可能会对应多个请求，对于衡量单个接口服务的处理能力，用 QPS 比较多。

**并发量**：系统能同时处理的请求数

**RT**：响应时间，处理一次请求所需要的平均处理时间

**吞吐量**：指在一次性能测试过程中网络上传输的数据量的总和。

对于交互式应用来说，吞吐量指标反映的是服务器承受的压力，在容量规划的测试中，吞吐量是一个重点关注的指标，因为它能够说明系统级别的负载能力，另外，在性能调优过程中，吞吐量指标也有重要的价值。如一个大型工厂，他们的生产效率与生产速度很快，一天生产 10W 吨的货物，结果工厂的运输能力不行，就两辆小型三轮车一天拉 2 吨的货物，比喻有些夸张，但我想说明的是这个运输能力是整个系统的瓶颈。

提示，用吞吐量来衡量一个系统的输出能力是极其不准确的，用个最简单的例子说明，一个水龙头开一天一夜，流出 10 吨水；10 个水龙头开 1 秒钟，流出 0.1 吨水。当然是一个水龙头的吞吐量大。你能说 1 个水龙头的出水能力是 10 个水龙头的强？所以，我们要加单位时间，看谁 1 秒钟的出水量大。这就是吞吐率。

**吞吐率：**单位时间内网络上传输的数据量，也可以指单位时间内处理客户请求数量。

**吞吐率**是衡量网络性能的重要指标，通常情况下，吞吐率用 “字节数 / 秒” 来衡量，当然，你可以用 “请求数 / 秒” 和“页面数 / 秒”来衡量。其实，不管是一个请求还是一个页面，它的本质都是在网络上传输的数据，那么来表示数据的单位就是字节数。

不过以不同的方式表达的吞吐量可以说明不同层次的问题。例如，以字节数 / 秒方式表示的吞吐量主要受网络基础设置、服务器架构、应用服务器制约；以请求数 / 秒方式表示的吞吐量主要受应用服务器和应用代码的制约。

但是从业务的角度看，吞吐率也可以用 “业务数 / 小时或天”、“访问人数 / 小时或天”、“页面访问量 / 小时或天” 来衡量。例如，在银行卡审批系统中，可以用 “千件 / 小时” 来衡量系统的业务处理能力。那么，从用户的角度，一个表单提交可以得到一次审批。又引出来一个概念 --- 事务。

**【QPS 计算 PV 和机器的方式】**

QPS **=** 请求数 / 秒，统计方式 一般使用 http_load 进行统计。  
QPS = 总请求数 / (进程总数 *   请求时间)  
QPS: 单个进程每秒请求服务器的成功次数

单台服务器每天 PV 计算  
公式 1：每天总 PV = QPS * 3600 * 6  
公式 2：每天总 PV = QPS * 3600 * 8

服务器计算  
服务器数量 =   ceil(每天总 PV / 单台服务器每天总 PV)

**【峰值 QPS 和机器计算公式】**

原理：每天 80% 的访问集中在 20% 的时间里，这 20% 时间叫做峰值时间  
公式：(总 PV 数 * 80%) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数 (QPS)  
机器：峰值时间每秒 QPS / 单台机器的 QPS   = 需要的机器

问：每天 300w PV 的在单台机器上，这台机器需要多少 QPS？  
答：(3000000 * 0.8) / (86400 * 0.2 ) = 139 (QPS)

问：如果一台机器的 QPS 是 58，需要几台机器来支持？  
答：139 / 58 = 3

注意：如果 r 经常大于 4 ，且 id 经常少于 40，表示 cpu 的负荷很重。

          如果 si，so 长期不等于 0，表示内存不足。

          如果 disk 经常不等于 0， 且在 b 中的队列大于 3， 表示 io 性能不好。

感谢您的支持，我会继续努力的! 扫码打赏，你说多少就多少

![](https://img-blog.csdn.net/20170331111807982)         ![](https://img-blog.csdn.net/20170331111745092)